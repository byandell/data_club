---
title: "Correlation"
output:
  html_document: default
  html_notebook: default
---

```{r libraries, message=FALSE}
library(dplyr)
library(ggplot2)
```

### Learning Objectives

* report on data sources and challenges
* plot and summarize single phenotype
* relate two phenotypes using correlation and regression
* imagine possible issues with experiment

### Read data

Here we read in data and reduce to species with counts at least 10.

```{r read}
surveys <- read.csv("../data/portal_data_joined.csv")
## Remove missing data.
surveys_complete <- surveys %>%
  filter(species_id != "", !is.na(weight)) %>%
  filter(!is.na(hindfoot_length), sex != "")
# count records per species
species_counts <- surveys_complete %>%
  group_by(species_id) %>%
  tally
# get names of the species with counts >= 10
frequent_species <-  species_counts %>%
  filter(n >= 10) %>%
  select(species_id)
# filter out the less-frequent species
surveys_complete <- surveys_complete %>%
  filter(species_id %in% frequent_species$species_id)
```

Now focus on one genus, `Dipodomys`.

```{r}
surveys_dip <- surveys_complete %>%
  filter(genus == "Dipodomys")
```

### Plot two phenotypes

Now we examine the two phenotypes against each other

```{r}
surveys_plot <- ggplot(surveys_dip, 
                       aes(x = weight, 
                           y = hindfoot_length))
```

```{r}
surveys_plot + 
  geom_point(alpha = 1, shape = 1) +
  scale_x_sqrt()
```

### Add a smooth line

```{r}
surveys_plot + 
  geom_point(alpha = 1, shape = 1, col = "gray") +
  scale_color_brewer(type="qualitative", palette = "Paired") +
  scale_x_sqrt() +
  geom_smooth()
```

Notice that the relationship is roughly linear for each species (fitable by straight lines).

### Correlation Coefficient

In practice we may have many phenotypes to examine, and it is useful to have a summary of how each pair of phenotypes are related. This is called correlation, computed using the `cor()` function. Look at the help page to learn about use.

```{r}
with(surveys_dip, cor(weight, hindfoot_length))
```

Just having one number is somewhat limited. In this case, there is a positive correlation (`r round(with(surveys_dip, cor(weight, hindfoot_length)), 2)`). But how do we interpret it?
The introductory book [_Statisticss_ by Freedman, Pisani and Purvis]() has a nice intrepretation, which is partially presented at [this website](http://www.analytictech.com/mb313/correlat.htm). Basically, if you look at the plot and see an increasing relationship, the correlation is roughly

```
cor = 1 - width / length
```

If the relationship is decreasing, the correlation is the opposite. 

```
cor = -(1 - width / length)
```

Thus you can get a rough idea of correlation with your eye, and over time build up an intuition of how strong correlation is in different settings.

#### Which correlation?

Correlation gives a sense of the relationship, but it depends on the sample size. With more data, a correlation coefficient is better estimated. The idea is that there is some relationship between two phenotypes, which we can estimate in terms of this correlation coefficient. With more data, we get a better estimate.

There are a variety of approaches to measuring correlation. What is generally done is to use the standard, or Pearson, correlation unless there are strong reasons to doubt a linear relationship. In that case the options are to transform the data (as we did above with `log2`) or use an approach that is less sensitive to linearity.

The non-linear approach, an example of non-parametric approaches, measures the degree of monotonic relationship by replacing the data with its ranks. 
The challenge with using measures based on ranks is that we lose some power to detect relationship by making fewer assumptions. Note also that if two phenotypes have the same rank order, then their Spearman correlation is 1, although their Pearson correlation might be somewhat less.

Here are several different ways to compute correlation, each with its own assumptions. They each give slightly different values. Clearly, there are many subtle issues here, and best to consult with a professional if you head down this path.

#### Correlation Test

```{r}
with(surveys_dip, cor.test(weight, hindfoot_length))
```

The significance of correlation depends on `df`, which is 2 less than sample size. In this case, the test is highly signficant. There is a confidence interval provided, which you will notice is typically not symmetric about the estimated correlation.

#### Linear Model interpretation of Correlation

An alternative test is to use the linear model function `lm()` to do the same thing. That is, `lm` tests the same linear relationship as does `cor.test`. 
Put another way, correlation and linear regression are two perspectives on the same relationship.

```{r}
fit <- lm(hindfoot_length ~ weight, surveys_dip)
summary(fit)
```

While there is a lot of output, notice that the `Coefficients` table has a column for `t value`. The `t value` for `log2(WBC)` is identical with the `t` from `cor.test`. Both are `r round(summary(fit)$coefficients["weight","t value"], 2)`.

We can go back to the plot and use a straight line instead of a smooth one:

```{r}
surveys_plot + 
  geom_point(alpha = 1, shape = 1) +
  scale_color_brewer(type="qualitative", palette = "Paired") +
  scale_x_sqrt() +
  geom_smooth(method="lm")
```
